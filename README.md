# Green Earth API

An API server for handling bluesky content recommendation requests.

## Prerequisites

- Python 3.13+
- pipenv

## Installation

1. Clone the repository

1. Install dependencies:

   ```bash
   pipenv install
   ```

1. Install development dependencies:

   ```bash
   pipenv install --dev
   ```

## Running the Server

Start the development server with auto-reload:

```bash
pipenv run uvicorn src.app.main:app --reload
```

The API will be available at `http://localhost:8000`

## Running Tests

Execute all tests:

```bash
pipenv run pytest
```

Run tests with verbose output:

```bash
pipenv run pytest -v
```

## API Endpoints

### Healthcheck

- **URL**: `/health`
- **Method**: `GET`
- **Success Response**:
  - **Code**: 200
  - **Content**: `{"status": "ok"}`

### Root

- **URL**: `/`
- **Method**: `GET`
- **Success Response**:
  - **Code**: 200
  - **Content**: `{"message": "Green Earth API"}`

## API Documentation

Interactive API documentation is automatically generated by FastAPI:

- **Swagger UI**: <http://localhost:8000/docs>
- **ReDoc**: <http://localhost:8000/redoc>

## Deployment

The API is deployed to Google Cloud Run using buildpacks.

### Prerequisites for Deployment

- [gcloud CLI](https://cloud.google.com/sdk/docs/install) installed and authenticated
- kubectl installed (for accessing Elasticsearch internal load balancer)
- Appropriate GCP project permissions

### First-Time Setup

Run the setup script once per environment to configure GCP resources:

```bash
# For staging environment (default)
./scripts/gcp_setup.sh

# For production environment
ENVIRONMENT=prod ./scripts/gcp_setup.sh

# With Elasticsearch API key
ELASTICSEARCH_API_KEY="your-api-key" ./scripts/gcp_setup.sh
```

This script will:

- Enable required GCP APIs (Cloud Run, Secret Manager, etc.)
- Create a service account with appropriate IAM roles
- Configure access to the Elasticsearch readonly API key in Secret Manager
- Verify VPC connector for internal network access

> **Note**: The API uses a separate readonly Elasticsearch API key (`elasticsearch-api-key-readonly`) 
> that only has read access. This key is created by running `scripts/k8s_recreate_api_key.sh` in the 
> ingex/ingest directory, which creates both the ingest (read/write) and API (readonly) keys.

### Deploying the Service

Deploy to Cloud Run:

```bash
# Deploy to staging (default)
./scripts/deploy.sh

# Deploy to production
ENVIRONMENT=prod ./scripts/deploy.sh

# Deploy with custom configuration
ENVIRONMENT=prod \
  API_INSTANCES_MIN=2 \
  API_INSTANCES_MAX=50 \
  ./scripts/deploy.sh
```

The deployment script will:

- Generate `requirements.txt` from `Pipfile`
- Auto-detect the Elasticsearch internal load balancer IP
- Build the container using Google Cloud buildpacks
- Deploy to Cloud Run with proper environment variables and secrets

### Configuration Options

You can override defaults using environment variables or command-line flags:

```bash
# Using environment variables
PROJECT_ID=your-project \
  REGION=us-west1 \
  ENVIRONMENT=prod \
  ELASTICSEARCH_URL=https://custom-es:9200 \
  ./scripts/deploy.sh

# Using command-line flags
./scripts/deploy.sh \
  --project-id your-project \
  --region us-west1 \
  --environment prod \
  --min-instances 2 \
  --max-instances 50
```

Available options:

- `PROJECT_ID` - GCP project ID (default: greenearth-471522)
- `REGION` - GCP region (default: us-east1)
- `ENVIRONMENT` - Environment name (default: stage)
- `ELASTICSEARCH_URL` - Elasticsearch endpoint (auto-detected if not set)
- `API_INSTANCES_MIN` - Minimum instances (default: 1)
- `API_INSTANCES_MAX` - Maximum instances (default: 10)

### Accessing the Deployed Service

After deployment, the script will output the service URL:

```text
Service URL: https://greenearth-api-<hash>-<region>.a.run.app
```

Test the deployed service:

```bash
# Health check
curl https://greenearth-api-<hash>-<region>.a.run.app/health

# API documentation
open https://greenearth-api-<hash>-<region>.a.run.app/docs
```

## Development Workflow

1. Create a new branch for your feature/fix
2. Make your changes incrementally
3. Run tests to ensure everything passes: `pipenv run pytest`
4. Commit your changes with descriptive messages
5. Push and create a pull request
6. After merge, deploy to staging: `./scripts/deploy.sh`
7. Test in staging, then deploy to production: `ENVIRONMENT=prod ./scripts/deploy.sh`

## Project Structure

```text
greenearth/api/
├── src/
│   └── app/
│       ├── __init__.py
│       ├── main.py              # FastAPI application entry point
│       └── routers/
│           ├── __init__.py
│           └── health.py        # Healthcheck endpoint
├── scripts/
│   ├── deploy.sh                # Cloud Run deployment script
│   └── gcp_setup.sh             # GCP environment setup script
├── tests/
│   ├── __init__.py
│   └── test_health.py           # Healthcheck tests
├── .gcloudignore                # Files to exclude from deployment
├── .python-version              # Python version for pyenv
├── Pipfile                      # pipenv dependencies
├── Procfile                     # Process definition for buildpacks
└── README.md                    # This file
```
